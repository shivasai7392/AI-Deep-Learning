{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07Nov_tfserving.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p4SVGdwQF_k"
      },
      "source": [
        "!pip install -q grpcio"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcwnE-EAP4fN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_9sKS4GQRZI",
        "outputId": "fe2f2819-c5d1-4ff1-a098-122c37490fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBnmzfoYQVsq"
      },
      "source": [
        "fashion = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tskFdM8MQjP8",
        "outputId": "9590b810-f7b0-4006-bf22-d1ab777e64b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNExtKIyQ3zi",
        "outputId": "66e27a96-bc75-4485-d5b0-1a7706dc958f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f19ecd6b320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwEm8Ck-RDhl",
        "outputId": "7bba04a5-1356-4470-a9f7-e97a6ec8c968",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJY1sBkRQcb"
      },
      "source": [
        "# 1. Preprocessing of images\n",
        "# 2. Preprocessing of lables -  one hot encoding\n",
        "# 3. Modelling\n",
        "# 4. Evaluate the model\n",
        "# 5. Deployment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOi3g6UWRooQ"
      },
      "source": [
        "x_train = x_train/255.0  #  ( image pixel value  range - 0 - 255 )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RjUVB_cSHQw"
      },
      "source": [
        "x_test = x_test/255.0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6qwJDjjSiQu"
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As2zdu8iS4Kq"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(8, (3,3),(1,1), activation='relu', input_shape = (28,28,1)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax')) #softmax provide probabalites of each class of  classification (all probablites equal to 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRt7QxnvVzkC"
      },
      "source": [
        "x_train = np.expand_dims(x_train, axis = -1)\n",
        "x_test = np.expand_dims(x_test, axis = -1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmcZMACCWEKE",
        "outputId": "26da78b4-c899-4dcb-8909-978a5746771c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnHAOq4cUrM9",
        "outputId": "a2eb5850-cc0e-4eb6-d05c-fe59f9c2ebe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss = tf.keras.losses.categorical_crossentropy, metrics= ['acc'])\n",
        "model.fit(x_train, y_train, epochs= 10, validation_split= 0.1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.4832 - acc: 0.8307 - val_loss: 0.3698 - val_acc: 0.8660\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 16s 9ms/step - loss: 0.3465 - acc: 0.8796 - val_loss: 0.3440 - val_acc: 0.8768\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 16s 9ms/step - loss: 0.3147 - acc: 0.8908 - val_loss: 0.3199 - val_acc: 0.8853\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 16s 9ms/step - loss: 0.2960 - acc: 0.8969 - val_loss: 0.3180 - val_acc: 0.8900\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 16s 9ms/step - loss: 0.2834 - acc: 0.9026 - val_loss: 0.3230 - val_acc: 0.8880\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 16s 9ms/step - loss: 0.2744 - acc: 0.9048 - val_loss: 0.3033 - val_acc: 0.8927\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.2668 - acc: 0.9085 - val_loss: 0.3162 - val_acc: 0.8923\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.2616 - acc: 0.9104 - val_loss: 0.3069 - val_acc: 0.8935\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.2567 - acc: 0.9129 - val_loss: 0.3115 - val_acc: 0.8940\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.2527 - acc: 0.9133 - val_loss: 0.3024 - val_acc: 0.8957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19e3a95cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiiSnGtgVRbx",
        "outputId": "9725f9c8-f5aa-4f05-c149-eba6587fb155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_path = \"fashion_minst/1\"\n",
        "model.save(model_path)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: fashion_minst/2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiJRBKOpW8DR",
        "outputId": "28c21510-ff0f-42fb-a349-fb2b1a8002b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0  37730      0 --:--:-- --:--:-- --:--:-- 37730\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Get:13 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [405 kB]\n",
            "Get:18 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.3 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,687 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,354 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,167 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,750 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,119 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [864 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [48.9 kB]\n",
            "Fetched 10.7 MB in 3s (3,387 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XpfZ4P2X14o",
        "outputId": "b8e2d882-b849-4423-b695-a7058218a0ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 210 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.3.0 [210 MB]\n",
            "Fetched 210 MB in 3s (67.8 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.3.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.3.0) ...\n",
            "Setting up tensorflow-model-server (2.3.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyIEC_PQbTJV",
        "outputId": "24be5bce-8a65-40f2-dd90-1b17a5a13cbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tensorflow_model_server --help"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: tensorflow_model_server\n",
            "Flags:\n",
            "\t--port=8500                      \tint32\tPort to listen on for gRPC API\n",
            "\t--grpc_socket_path=\"\"            \tstring\tIf non-empty, listen to a UNIX socket for gRPC API on the given path. Can be either relative or absolute path.\n",
            "\t--rest_api_port=0                \tint32\tPort to listen on for HTTP/REST API. If set to zero HTTP/REST API will not be exported. This port must be different than the one specified in --port.\n",
            "\t--rest_api_num_threads=8         \tint32\tNumber of threads for HTTP/REST API processing. If not set, will be auto set based on number of CPUs.\n",
            "\t--rest_api_timeout_in_ms=30000   \tint32\tTimeout for HTTP/REST API calls.\n",
            "\t--enable_batching=false          \tbool\tenable batching\n",
            "\t--allow_version_labels_for_unavailable_models=false\tbool\tIf true, allows assigning unused version labels to models that are not available yet.\n",
            "\t--batching_parameters_file=\"\"    \tstring\tIf non-empty, read an ascii BatchingParameters protobuf from the supplied file name and use the contained values instead of the defaults.\n",
            "\t--model_config_file=\"\"           \tstring\tIf non-empty, read an ascii ModelServerConfig protobuf from the supplied file name, and serve the models in that file. This config file can be used to specify multiple models to serve and other advanced parameters including non-default version policy. (If used, --model_name, --model_base_path are ignored.)\n",
            "\t--model_config_file_poll_wait_seconds=0\tint32\tInterval in seconds between each poll of the filesystemfor model_config_file. If unset or set to zero, poll will be done exactly once and not periodically. Setting this to negative is reserved for testing purposes only.\n",
            "\t--model_name=\"default\"           \tstring\tname of model (ignored if --model_config_file flag is set)\n",
            "\t--model_base_path=\"\"             \tstring\tpath to export (ignored if --model_config_file flag is set, otherwise required)\n",
            "\t--max_num_load_retries=5         \tint32\tmaximum number of times it retries loading a model after the first failure, before giving up. If set to 0, a load is attempted only once. Default: 5\n",
            "\t--load_retry_interval_micros=60000000\tint64\tThe interval, in microseconds, between each servable load retry. If set negative, it doesn't wait. Default: 1 minute\n",
            "\t--file_system_poll_wait_seconds=1\tint32\tInterval in seconds between each poll of the filesystem for new model version. If set to zero poll will be exactly done once and not periodically. Setting this to negative value will disable polling entirely causing ModelServer to indefinitely wait for a new model at startup. Negative values are reserved for testing purposes only.\n",
            "\t--flush_filesystem_caches=true   \tbool\tIf true (the default), filesystem caches will be flushed after the initial load of all servables, and after each subsequent individual servable reload (if the number of load threads is 1). This reduces memory consumption of the model server, at the potential cost of cache misses if model files are accessed after servables are loaded.\n",
            "\t--tensorflow_session_parallelism=0\tint64\tNumber of threads to use for running a Tensorflow session. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
            "\t--tensorflow_intra_op_parallelism=0\tint64\tNumber of threads to use to parallelize the executionof an individual op. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
            "\t--tensorflow_inter_op_parallelism=0\tint64\tControls the number of operators that can be executed simultaneously. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
            "\t--ssl_config_file=\"\"             \tstring\tIf non-empty, read an ascii SSLConfig protobuf from the supplied file name and set up a secure gRPC channel\n",
            "\t--platform_config_file=\"\"        \tstring\tIf non-empty, read an ascii PlatformConfigMap protobuf from the supplied file name, and use that platform config instead of the Tensorflow platform. (If used, --enable_batching is ignored.)\n",
            "\t--per_process_gpu_memory_fraction=0.000000\tfloat\tFraction that each process occupies of the GPU memory space the value is between 0.0 and 1.0 (with 0.0 as the default) If 1.0, the server will allocate all the memory when the server starts, If 0.0, Tensorflow will automatically select a value.\n",
            "\t--saved_model_tags=\"serve\"       \tstring\tComma-separated set of tags corresponding to the meta graph def to load from SavedModel.\n",
            "\t--grpc_channel_arguments=\"\"      \tstring\tA comma separated list of arguments to be passed to the grpc server. (e.g. grpc.max_connection_age_ms=2000)\n",
            "\t--enable_model_warmup=true       \tbool\tEnables model warmup, which triggers lazy initializations (such as TF optimizations) at load time, to reduce first request latency.\n",
            "\t--version=false                  \tbool\tDisplay version\n",
            "\t--monitoring_config_file=\"\"      \tstring\tIf non-empty, read an ascii MonitoringConfig protobuf from the supplied file name\n",
            "\t--remove_unused_fields_from_bundle_metagraph=true\tbool\tRemoves unused fields from MetaGraphDef proto message to save memory.\n",
            "\t--prefer_tflite_model=false      \tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Prefer TensorFlow Lite model from `model.tflite` file in SavedModel directory, instead of the TensorFlow model from `saved_model.pb` file. If no TensorFlow Lite model found, fallback to TensorFlow model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e0iflsXZCvz",
        "outputId": "59f1a2b9-a363-4237-9aaa-8963f974920e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "--rest_api_port=8501 \\\n",
        "--model_name=fashion_minst \\\n",
        "--model_base_path=/content/fashion_minst > server.log 2>&1"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 2 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xJpkABAbdm-",
        "outputId": "91ad1f3e-ac1b-427a-9c70-ed61b9253d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! cat server.log"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-07 16:01:25.977582: I tensorflow_serving/model_servers/server.cc:87] Building single TensorFlow model file config:  model_name: fashion_minst model_base_path: /content/fashion_minst\n",
            "2020-11-07 16:01:25.977890: I tensorflow_serving/model_servers/server_core.cc:464] Adding/updating models.\n",
            "2020-11-07 16:01:25.977926: I tensorflow_serving/model_servers/server_core.cc:575]  (Re-)adding model: fashion_minst\n",
            "2020-11-07 16:01:26.078540: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: fashion_minst version: 2}\n",
            "2020-11-07 16:01:26.078588: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: fashion_minst version: 2}\n",
            "2020-11-07 16:01:26.078601: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: fashion_minst version: 2}\n",
            "2020-11-07 16:01:26.078646: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /content/fashion_minst/2\n",
            "2020-11-07 16:01:26.080063: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
            "2020-11-07 16:01:26.080113: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:234] Reading SavedModel debug info (if present) from: /content/fashion_minst/2\n",
            "2020-11-07 16:01:26.080203: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-11-07 16:01:26.106198: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:199] Restoring SavedModel bundle.\n",
            "2020-11-07 16:01:26.128328: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:183] Running initialization op on SavedModel bundle at path: /content/fashion_minst/2\n",
            "2020-11-07 16:01:26.132460: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:303] SavedModel load for tags { serve }; Status: success: OK. Took 53798 microseconds.\n",
            "2020-11-07 16:01:26.133060: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /content/fashion_minst/2/assets.extra/tf_serving_warmup_requests\n",
            "2020-11-07 16:01:26.133199: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: fashion_minst version: 2}\n",
            "2020-11-07 16:01:26.134491: I tensorflow_serving/model_servers/server.cc:367] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2020-11-07 16:01:26.135361: I tensorflow_serving/model_servers/server.cc:387] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKoKpJDDbjn8",
        "outputId": "3eb8b95a-8d44-4fd0-e963-8220e1084a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(x_test[10, :, :, 0])\n",
        "y_test[10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dh9-0k5dJ-f",
        "outputId": "2b42c55f-0432-4c9a-c7d3-5ad89cfc21da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.predict(np.expand_dims(x_test[10], 0))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4532582e-04, 1.4544665e-05, 3.0870605e-02, 1.3250641e-06,\n",
              "        9.3685454e-01, 1.9638687e-06, 3.2107580e-02, 9.3743256e-11,\n",
              "        4.0504019e-06, 4.1281744e-08]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXw34wjTdrH4",
        "outputId": "6d8a7213-cba1-428e-eb0d-ba8cda437e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.argmax(model.predict(np.expand_dims(x_test[10], 0)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0vMbFRld145"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": np.expand_dims(x_test[10], 0).tolist() })\n",
        "# remember dont send the np-array in data json please convert it to list"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op4Tl6cResnA",
        "outputId": "546556f7-2743-4448-b616-4da1db480655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"signature_name\": \"serving_default\", \"instances\": [[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5686274509803921], [0.7450980392156863], [0.3803921568627451], [0.42745098039215684], [0.4117647058823529], [0.7333333333333333], [0.2980392156862745], [0.0], [0.0], [0.0], [0.00784313725490196], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.25098039215686274], [0.6666666666666666], [0.6392156862745098], [0.8156862745098039], [0.9529411764705882], [0.9411764705882353], [0.8980392156862745], [0.6784313725490196], [0.6352941176470588], [0.6039215686274509], [0.07058823529411765], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.15294117647058825], [0.6196078431372549], [0.7686274509803922], [0.5843137254901961], [0.7490196078431373], [0.7803921568627451], [0.8745098039215686], [0.9529411764705882], [0.7294117647058823], [0.7490196078431373], [0.6666666666666666], [0.6078431372549019], [0.6352941176470588], [0.49411764705882355], [0.08627450980392157], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.011764705882352941], [0.0], [0.4117647058823529], [0.6313725490196078], [0.5882352941176471], [0.5529411764705883], [0.5098039215686274], [0.7803921568627451], [0.9372549019607843], [0.8980392156862745], [0.8627450980392157], [0.7372549019607844], [0.9568627450980393], [0.5686274509803921], [0.5019607843137255], [0.5568627450980392], [0.592156862745098], [0.6862745098039216], [0.09019607843137255], [0.0], [0.00784313725490196], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5882352941176471], [0.5372549019607843], [0.5254901960784314], [0.5098039215686274], [0.5764705882352941], [0.4745098039215686], [0.9450980392156862], [1.0], [0.4470588235294118], [0.9411764705882353], [0.6784313725490196], [0.5568627450980392], [0.5333333333333333], [0.5176470588235295], [0.5019607843137255], [0.6], [0.44313725490196076], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.06666666666666667], [0.615686274509804], [0.5058823529411764], [0.5725490196078431], [0.5843137254901961], [0.5372549019607843], [0.5529411764705883], [0.6941176470588235], [0.7843137254901961], [0.7843137254901961], [0.8117647058823529], [0.5254901960784314], [0.5686274509803921], [0.5568627450980392], [0.5490196078431373], [0.5176470588235295], [0.5058823529411764], [0.5490196078431373], [0.011764705882352941], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.19607843137254902], [0.6196078431372549], [0.5372549019607843], [0.6], [0.5882352941176471], [0.49019607843137253], [0.6078431372549019], [0.7490196078431373], [0.6862745098039216], [0.5529411764705883], [0.6470588235294118], [0.6509803921568628], [0.6], [0.5098039215686274], [0.5058823529411764], [0.5176470588235295], [0.5529411764705883], [0.5843137254901961], [0.07058823529411765], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.30196078431372547], [0.6509803921568628], [0.6313725490196078], [0.5372549019607843], [0.592156862745098], [0.6509803921568628], [0.7098039215686275], [0.8470588235294118], [0.7137254901960784], [0.6196078431372549], [0.8431372549019608], [0.7647058823529411], [0.6078431372549019], [0.6235294117647059], [0.6352941176470588], [0.6784313725490196], [0.5882352941176471], [0.5882352941176471], [0.22745098039215686], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.40784313725490196], [0.6235294117647059], [0.6666666666666666], [0.5490196078431373], [0.5176470588235295], [0.7137254901960784], [0.7764705882352941], [0.8156862745098039], [0.6862745098039216], [0.5333333333333333], [0.6823529411764706], [0.6627450980392157], [0.5764705882352941], [0.6078431372549019], [0.4745098039215686], [0.7372549019607844], [0.6352941176470588], [0.5568627450980392], [0.396078431372549], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.4392156862745098], [0.6705882352941176], [0.807843137254902], [0.7019607843137254], [0.5764705882352941], [0.6392156862745098], [0.6941176470588235], [0.7686274509803922], [0.7529411764705882], [0.5725490196078431], [0.7333333333333333], [0.6], [0.5568627450980392], [0.5647058823529412], [0.5333333333333333], [0.9607843137254902], [0.792156862745098], [0.5176470588235295], [0.5372549019607843], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.49411764705882355], [0.7098039215686275], [0.8588235294117647], [0.5725490196078431], [0.615686274509804], [0.5019607843137255], [0.4745098039215686], [0.6862745098039216], [0.7686274509803922], [0.40784313725490196], [0.615686274509804], [0.6196078431372549], [0.592156862745098], [0.5490196078431373], [0.403921568627451], [0.34901960784313724], [0.8666666666666667], [0.5529411764705883], [0.6], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.615686274509804], [0.6862745098039216], [0.8470588235294118], [0.21568627450980393], [0.6862745098039216], [0.6], [0.592156862745098], [0.7372549019607844], [0.8392156862745098], [0.49411764705882355], [0.8], [0.6235294117647059], [0.5686274509803921], [0.5686274509803921], [0.4549019607843137], [0.2784313725490196], [0.8313725490196079], [0.6039215686274509], [0.6078431372549019], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.7176470588235294], [0.6392156862745098], [0.9098039215686274], [0.25098039215686274], [0.5411764705882353], [0.5568627450980392], [0.7137254901960784], [0.7647058823529411], [0.7843137254901961], [0.6196078431372549], [0.9058823529411765], [0.5725490196078431], [0.5098039215686274], [0.6313725490196078], [0.5176470588235295], [0.4117647058823529], [0.8823529411764706], [0.5725490196078431], [0.615686274509804], [0.0392156862745098], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.023529411764705882], [0.7372549019607844], [0.6313725490196078], [0.8666666666666667], [0.21176470588235294], [0.5843137254901961], [0.6470588235294118], [0.592156862745098], [0.6549019607843137], [0.7372549019607844], [0.6666666666666666], [0.7098039215686275], [0.6039215686274509], [0.5529411764705883], [0.5098039215686274], [0.5647058823529412], [0.36470588235294116], [0.8117647058823529], [0.6509803921568628], [0.5568627450980392], [0.13333333333333333], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.16470588235294117], [0.7137254901960784], [0.6470588235294118], [0.9254901960784314], [0.11372549019607843], [0.5725490196078431], [0.6666666666666666], [0.5529411764705883], [0.6509803921568628], [0.8156862745098039], [0.48627450980392156], [0.6352941176470588], [0.6784313725490196], [0.6039215686274509], [0.5176470588235295], [0.5490196078431373], [0.3803921568627451], [0.7607843137254902], [0.6], [0.6313725490196078], [0.1843137254901961], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.22745098039215686], [0.6862745098039216], [0.6705882352941176], [0.7490196078431373], [0.0196078431372549], [0.6784313725490196], [0.6352941176470588], [0.6039215686274509], [0.7098039215686275], [0.8117647058823529], [0.39215686274509803], [0.6313725490196078], [0.7019607843137254], [0.6078431372549019], [0.5725490196078431], [0.5843137254901961], [0.2980392156862745], [0.7529411764705882], [0.6352941176470588], [0.5882352941176471], [0.24313725490196078], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.3137254901960784], [0.7019607843137254], [0.6509803921568628], [0.6549019607843137], [0.0392156862745098], [0.7137254901960784], [0.592156862745098], [0.615686274509804], [0.6980392156862745], [0.7215686274509804], [0.6509803921568628], [0.8156862745098039], [0.6823529411764706], [0.5411764705882353], [0.5725490196078431], [0.5490196078431373], [0.28627450980392155], [0.7294117647058823], [0.6313725490196078], [0.6078431372549019], [0.2784313725490196], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.39215686274509803], [0.6470588235294118], [0.6705882352941176], [0.5411764705882353], [0.2], [0.7607843137254902], [0.615686274509804], [0.5215686274509804], [0.7333333333333333], [0.7686274509803922], [0.6509803921568628], [0.7764705882352941], [0.6392156862745098], [0.5058823529411764], [0.5568627450980392], [0.5254901960784314], [0.28627450980392155], [0.7490196078431373], [0.6039215686274509], [0.6078431372549019], [0.30980392156862746], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.42745098039215684], [0.6196078431372549], [0.6862745098039216], [0.4627450980392157], [0.28627450980392155], [0.7019607843137254], [0.5725490196078431], [0.5843137254901961], [0.7176470588235294], [0.8117647058823529], [0.5529411764705883], [0.7215686274509804], [0.6705882352941176], [0.6], [0.5372549019607843], [0.5764705882352941], [0.28627450980392155], [0.7647058823529411], [0.615686274509804], [0.6039215686274509], [0.3333333333333333], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.42745098039215684], [0.6392156862745098], [0.7019607843137254], [0.47843137254901963], [0.4549019607843137], [0.6941176470588235], [0.5647058823529412], [0.6470588235294118], [0.7137254901960784], [0.7450980392156863], [0.5764705882352941], [0.7019607843137254], [0.6352941176470588], [0.5725490196078431], [0.5215686274509804], [0.6], [0.3803921568627451], [0.6313725490196078], [0.6196078431372549], [0.5882352941176471], [0.37254901960784315], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.4196078431372549], [0.6196078431372549], [0.6549019607843137], [0.6392156862745098], [0.4117647058823529], [0.5372549019607843], [0.6313725490196078], [0.6392156862745098], [0.796078431372549], [0.7803921568627451], [0.5843137254901961], [0.7098039215686275], [0.6549019607843137], [0.6313725490196078], [0.5764705882352941], [0.5764705882352941], [0.38823529411764707], [0.6509803921568628], [0.615686274509804], [0.5529411764705883], [0.38823529411764707], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.42745098039215684], [0.6039215686274509], [0.6509803921568628], [0.5686274509803921], [0.0], [0.13333333333333333], [0.32941176470588235], [0.24705882352941178], [0.4196078431372549], [0.5843137254901961], [0.5176470588235295], [0.6], [0.5058823529411764], [0.48627450980392156], [0.5843137254901961], [0.2196078431372549], [0.0], [0.4470588235294118], [0.6235294117647059], [0.5529411764705883], [0.3803921568627451], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.4235294117647059], [0.6039215686274509], [0.6627450980392157], [0.3333333333333333], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.00784313725490196], [0.03529411764705882], [0.0], [0.0], [0.0], [0.0], [0.0], [0.36470588235294116], [0.615686274509804], [0.5568627450980392], [0.38823529411764707], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.396078431372549], [0.6], [0.6627450980392157], [0.3137254901960784], [0.0], [0.011764705882352941], [0.0], [0.00392156862745098], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.00392156862745098], [0.0], [0.3137254901960784], [0.6078431372549019], [0.5647058823529412], [0.4117647058823529], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.4745098039215686], [0.615686274509804], [0.6509803921568628], [0.2980392156862745], [0.0], [0.011764705882352941], [0.0], [0.0], [0.00392156862745098], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.011764705882352941], [0.0], [0.2627450980392157], [0.6352941176470588], [0.5529411764705883], [0.39215686274509803], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.48627450980392156], [0.6], [0.6352941176470588], [0.2], [0.0], [0.011764705882352941], [0.0], [0.0], [0.0], [0.0], [0.0], [0.00392156862745098], [0.0], [0.00392156862745098], [0.0], [0.0196078431372549], [0.0], [0.22745098039215686], [0.6549019607843137], [0.5725490196078431], [0.3411764705882353], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.47843137254901963], [0.6470588235294118], [0.7098039215686275], [0.21176470588235294], [0.0], [0.0196078431372549], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0196078431372549], [0.0], [0.21176470588235294], [0.6666666666666666], [0.5490196078431373], [0.29411764705882354], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.09803921568627451], [0.29411764705882354], [0.3607843137254902], [0.011764705882352941], [0.0], [0.00392156862745098], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.011764705882352941], [0.0], [0.11372549019607843], [0.5686274509803921], [0.5372549019607843], [0.23137254901960785], [0.0], [0.0], [0.0]]]]}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIgNsqMbe2FN",
        "outputId": "b5ea526b-eb5d-4cf3-cf6a-9472f716a83f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "num=54\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": np.expand_dims(x_test[num], 0).tolist() })\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_respone = requests.post(\"http://localhost:8501/v1/models/fashion_minst:predict\", data=data, headers=headers)\n",
        "pred = json.loads(json_respone.text)[\"predictions\"]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 ms, sys: 966 µs, total: 4.96 ms\n",
            "Wall time: 5.11 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JamGKgdifYyT"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3g9SMJefcFN",
        "outputId": "506132c0-c1c3-4319-f229-5348572ba15d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.argmax(pred), y_test[num]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfXlOT8Df8Ut"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}